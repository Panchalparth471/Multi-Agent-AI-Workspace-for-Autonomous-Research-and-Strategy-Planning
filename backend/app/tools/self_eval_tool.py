import os
from langchain.tools import Tool
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain_groq import ChatGroq
from pydantic import BaseModel, Field

class SelfEvalInput(BaseModel):
    step_type: str = Field(..., description="The type of step (e.g. Research, Plan, Analyze, Validate)")
    input_context: str = Field(..., description="The input or context for the step")
    output: str = Field(..., description="The output generated by the step")

def get_self_eval_tool():
    llm = ChatGroq(
        groq_api_key=os.getenv("GROQ_API_KEY"),
        model="llama3-70b-8192"
    )

    prompt = PromptTemplate.from_template("""
You are a critical self-evaluator.

Evaluate the following step result ONLY and STRICTLY in this JSON format (no extra text, no explanation):

```json
{{
  "rating": <integer from 1 to 5>,
  "feedback": "<short and concise analysis>",
  "suggestions": "<concrete suggestions for improvement or 'None'>"
}}
Step Type: {step_type}
Input Context: {input_context}
Output Produced: {output}
""")

    chain = LLMChain(llm=llm, prompt=prompt)

    def wrapped_func(input_dict: dict) -> str:
        return chain.run({
            "step_type": input_dict.get("step_type", ""),
            "input_context": input_dict.get("input_context", ""),
            "output": input_dict.get("output", "")
        })

    return Tool(
        name="Self-Evaluator",
        func=wrapped_func,
        description="Evaluates agent step outputs for quality and provides feedback.",
        args=SelfEvalInput  # <-- pass your pydantic model here
    )
